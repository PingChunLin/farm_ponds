{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Farm ponds recognition model training\n",
    "This is a notebook to train a MaskRCNN model to recognize farm ponds in satellite images. The code is based on Detectron2 documentation. You can find more details of the pre-train models from [Meta Research's Github repository](https://github.com/facebookresearch/detectron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1688167702071,
     "user": {
      "displayName": "Ping-Chun Lin",
      "userId": "07833352389779309997"
     },
     "user_tz": 420
    },
    "id": "0d288Z2mF5dC",
    "outputId": "1a93db01-087a-4256-ae2b-c961354fb4d2"
   },
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Kadwanchi Data\n",
    "\n",
    "This is a test on of the trained model from Kadwanchi. To use a pre-trained model, you will need the config file of a pretrained model(yaml) and the model weights (pth). The pre-trained model needs pred_mask to color the area of the farm ponds. You can swap the test folder path to other image sets to test and visualize the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from itertools import compress\n",
    "from PIL import Image  \n",
    "from skimage import io, color, segmentation\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('path to config file')\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the trained model \n",
    "predictor = DefaultPredictor(cfg)\n",
    "pond_metadata = MetadataCatalog.get(\"pond_train\")\n",
    "\n",
    "\n",
    "test_folder_path = 'test folder path'\n",
    "output_folder = 'mask output folder path'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "image_files = [file for file in os.listdir(test_folder_path) if file.lower().endswith(('.png'))]\n",
    "\n",
    "def cropper(org_image_path, mask_array, out_file_name):\n",
    "    num_instances = mask_array.shape[0]\n",
    "    mask_array = np.moveaxis(mask_array, 0, -1)\n",
    "    mask_array_instance = []\n",
    "    img = cv2.imread(str(org_image_path))\n",
    "    output = np.zeros_like(img)\n",
    "    for i in range(num_instances):\n",
    "        mask_array_instance.append(mask_array[:, :, i:(i+1)])\n",
    "        output = np.where(mask_array_instance[i] == True, 255, output)\n",
    "    im = Image.fromarray(output)\n",
    "    im.save(out_file_name)\n",
    "\n",
    "\n",
    "# Loop through each image file\n",
    "for d in image_files:\n",
    "    im_path = os.path.join(test_folder_path, d)\n",
    "    im = cv2.imread(im_path)\n",
    "    outputs = predictor(im)\n",
    "    masks = outputs['instances'].pred_masks\n",
    "    masks= masks.to('cpu').numpy()\n",
    "    #num, h, w= masks.shape\n",
    "    mask_path = os.path.join(output_folder, d)\n",
    "    cropper(im_path, masks, mask_path)\n",
    "    \n",
    "\n",
    "# Show three random samples\n",
    "for d in random.sample(image_files, 3):\n",
    "    im_path = os.path.join(test_folder_path, d)\n",
    "    print(im_path)\n",
    "    im = cv2.imread(im_path)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=pond_metadata,\n",
    "                   scale=0.5,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5",
     "timestamp": 1688164861181
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "d2",
   "language": "python",
   "name": "d2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
