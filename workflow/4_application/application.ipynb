{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Farm ponds identification pipeline: Applications\n",
    "Before you start this notebook, make sure that you have\n",
    "- Pretrained model configuration: ```config.pkl``` in the [parameters folder](../../output/parameters/)\n",
    "- Tiles of the satellite image: ```tile_x_y.png``` in [train](../../data/train/) and [val](../../data/val/) folders\n",
    "- Tiles of the masks: ```tile_x_y.png``` in [train_mask](../../data/train_mask/) and [val_mask](../../data/val_mask/) folders\n",
    "\n",
    " The tiles and the mask should follow the naming scheme: ```tile_x_y.png```, where x is the top left coordinates ```(x,y)``` of the image (in pixles). \n",
    "\n",
    "## Install the packages for the pipeline\n",
    "Make sure you have the environment set up done, so that we can import the packages used in this notebook. Check out the [setup info](../../README.md). Traning the instance segmentation model requires ```torch``` and ```detectron2```, so here we need to install the libraries first. You can skip this step if you already installed ```detectron2``` in the previous steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries that are used in the pipeline\n",
    "Part of the libraries and requirements used in this pipeline are based on Detectron2 documentation. You can find more details of the pre-train models from [Meta Research's Github repository](https://github.com/facebookresearch/detectron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1688167702071,
     "user": {
      "displayName": "Ping-Chun Lin",
      "userId": "07833352389779309997"
     },
     "user_tz": 420
    },
    "id": "0d288Z2mF5dC",
    "outputId": "1a93db01-087a-4256-ae2b-c961354fb4d2"
   },
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import DatasetMapper, build_detection_train_loader\n",
    "import cloudpickle\n",
    "from detectron2.config import CfgNode\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "ponds_root = os.path.dirname(os.path.dirname(os.getcwd())) \n",
    "if ponds_root not in sys.path:\n",
    "    sys.path.append(ponds_root)\n",
    "\n",
    "train_image_path = os.path.join(ponds_root, \"data/train.png\")  # Path to the input image\n",
    "train_mask_path =  os.path.join(ponds_root,\"data/train_mask.png\")\n",
    "train_folder =  os.path.join(ponds_root,\"data/train/\")  # Output folder for tiles\n",
    "train_mask_folder =  os.path.join(ponds_root,\"data/train_mask/\")\n",
    "train_not_used_folder =  os.path.join(ponds_root,\"data/train_not_used/\")\n",
    "val_folder =  os.path.join(ponds_root,\"data/val/\")\n",
    "val_mask_folder =   os.path.join(ponds_root,\"data/val_mask/\")\n",
    "output_folder = os.path.join(ponds_root, \"output/\")\n",
    "parameter_folder = os.path.join(output_folder, \"parameters/\")\n",
    "model_folder = os.path.join(output_folder, \"model/\")\n",
    "performance_folder = os.path.join(output_folder, \"performance/\")\n",
    "inference_path = os.path.join(performance_folder, \"inference.txt\")\n",
    "\n",
    "best_performance_path = os.path.join(performance_folder, \"best_performance.txt\")\n",
    "test_image_path = os.path.join(ponds_root, \"data/test.png\")  \n",
    "test_folder = os.path.join(ponds_root,\"data/test/\")\n",
    "test_mask_folder = os.path.join(ponds_root,\"data/test_mask/\")\n",
    "test_array_folder = os.path.join(ponds_root,\"data/test_array/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import preprocess as prep\n",
    "from utils import helpers as hp\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"pond_train\", {}, os.path.join(train_folder,\"train.json\"), train_folder)\n",
    "register_coco_instances(\"pond_val\", {}, os.path.join(val_folder,\"val.json\"), val_folder)\n",
    "pond_metadata = MetadataCatalog.get(\"pond_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "best_paths = hp.read_paths_from_file(best_performance_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0e4vdDIOXyxF"
   },
   "source": [
    "## Load the pre-trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ya5nEuMELeq8"
   },
   "outputs": [],
   "source": [
    "cfg = hp.load_from_cloudpickle(best_paths[1])\n",
    "cfg.MODEL.WEIGHTS = best_paths[0]  # path to the trained model \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Kadwanchi Data\n",
    "\n",
    "This is a test on of of the imagery for Kadwanchi, India. You can swap the test image here to any other satellite image. You can also skip the next cell if you already have image tiles instead of the complete image. The resolution is 1024x1024 pixel for each tile. The Ground Sample Distance (GSD) for ths image is 30cm/px. We recommend the same resolution as the training set for the best prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None\n",
    "test_image_path = os.path.join(ponds_root,\"data/test.png\")\n",
    "test_folder = os.path.join(ponds_root,\"data/test/\")\n",
    "min_image_size = 100000  # < 3800 is empty\n",
    "tile_width, tile_height = 1024, 1024  # Tile dimensions\n",
    "\n",
    "prep.divide_and_save_image(test_image_path, test_folder, tile_width, tile_height)\n",
    "prep.filter_tiles_by_size(test_folder, min_image_size) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from itertools import compress\n",
    "from skimage import io, color, segmentation\n",
    "\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "os.makedirs(test_mask_folder, exist_ok=True)\n",
    "image_files = [file for file in os.listdir(test_folder) if file.lower().endswith(('.png'))]\n",
    "\n",
    "def cropper(org_image_path, mask_array, out_file_name):\n",
    "    num_instances = mask_array.shape[0]\n",
    "    mask_array = np.moveaxis(mask_array, 0, -1)\n",
    "    mask_array_instance = []\n",
    "    img = cv2.imread(str(org_image_path))\n",
    "    output = np.zeros_like(img)\n",
    "    for i in range(num_instances):\n",
    "        mask_array_instance.append(mask_array[:, :, i:(i+1)])\n",
    "        output = np.where(mask_array_instance[i] == True, 255, output)\n",
    "    im = Image.fromarray(output)\n",
    "    im.save(out_file_name)\n",
    "\n",
    "\n",
    "# Loop through each image file\n",
    "for d in image_files:\n",
    "    im_path = os.path.join(test_folder, d)\n",
    "    im = cv2.imread(im_path)\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    masks = outputs['instances'].pred_masks\n",
    "    masks= masks.to('cpu').numpy()\n",
    "    #num, h, w= masks.shape\n",
    "    mask_path = os.path.join(test_mask_folder, d)\n",
    "    cropper(im_path, masks, mask_path)\n",
    "    \n",
    "\n",
    "# Show five random samples\n",
    "for d in random.sample(image_files, 5):\n",
    "    im_path = os.path.join(test_folder, d)\n",
    "    print(im_path)\n",
    "    im = cv2.imread(im_path)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=pond_metadata,\n",
    "                   scale=0.5,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing\n",
    "\n",
    "### Mosaic\n",
    "\n",
    "This part of the code stiches all the tiles together based on their locations on the image. \n",
    " - Input: The test mask folder\n",
    " - Output: A merged PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.mosaic as mosc\n",
    "os.makedirs(test_mask_folder, exist_ok=True)\n",
    "os.makedirs(test_array_folder, exist_ok=True)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "mosc.process_directory(test_mask_folder, test_array_folder)\n",
    "sorted_filenames = mosc.load_and_sort_filenames(test_array_folder)\n",
    "merged_array, failed_list = mosc.merge_tiles(sorted_filenames, test_array_folder, (14849, 20937))\n",
    "merged_image_path = os.path.join(output_folder, \"merged_predictions.png\")\n",
    "mosc.save_merged_image(merged_array, merged_image_path)\n",
    "output_txt_path = os.path.join(output_folder, \"tiles_failed_to_count.txt\")\n",
    "mosc.save_failed_list(failed_list, output_txt_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Georeferencing\n",
    "\n",
    "This cell will geolocate the farmponds and assign coordinates (langitude, longitude) to the prediction results. You can skip this cell if you use a GIS software such QGIS as to perform georeferencing manually. Our example below uses a QGIS georeferenced TIF to obtain the best geolocations for the ponds. Please see the georeferencing tutorial for QGIS here: [https://docs.qgis.org/3.34/en/docs/user_manual/working_with_raster/georeferencer.html](https://docs.qgis.org/3.34/en/docs/user_manual/working_with_raster/georeferencer.html)\n",
    "\n",
    " - Input: The merged_predictions.png, the longitude and latitude of the four corners of the image\n",
    " - Output: A merged_predictions.tif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.georeference as georef\n",
    "# Configuration - Replace these with your actual file paths and coordinates\n",
    "georef_input_png = os.path.join(output_folder, \"merged_predictions.png\")\n",
    "output_geotiff = os.path.join(output_folder, \"georeferenced.tif\")\n",
    "top_left_x, top_left_y = 75.97936000, 19.94643500  # NW corner: Longitude, Latitude\n",
    "bottom_right_x, bottom_right_y = 76.02171400, 19.88961000  # SE corner: Longitude, Latitude\n",
    "\n",
    "dst_ds = georef.create_geotiff_copy(georef_input_png, output_geotiff)\n",
    "geotransform = georef.calculate_geotransform_parameters(dst_ds, top_left_x, top_left_y, bottom_right_x, bottom_right_y)\n",
    "georef.assign_geotransform_and_projection(dst_ds, geotransform)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Calculation\n",
    "\n",
    "This cell estimates the surface area of each labeled pond on the satellite image and creates a spreadsheet (CSV)that includes the location and area. \n",
    "\n",
    " - Input: The georeferenced.tif\n",
    " - Output: A CSV of the instance area estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.area_calculator as ac\n",
    "ac_input_tif = os.path.join(output_folder, \"georeferenced.tif\")\n",
    "ac_output_csv = os.path.join(output_folder, \"area_estimate.csv\")\n",
    "ac_output_png = os.path.join(output_folder, \"labeled_instances.png\")\n",
    "\n",
    "image, thresholded = ac.load_and_threshold_image(ac_input_tif)\n",
    "contours = ac.find_contours(thresholded)\n",
    "geotransform, transform = ac.setup_coordinate_transformation(ac_input_tif)\n",
    "if geotransform and transform:\n",
    "    data = ac.calculate_objects_data(contours, geotransform, transform)\n",
    "    ac.save_data_and_image(data, image, ac_output_csv, ac_output_png)\n",
    "else:\n",
    "    print(\"Failed to perform coordinate transformation. Exiting.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5",
     "timestamp": 1688164861181
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "d2",
   "language": "python",
   "name": "d2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
